{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57052cdc-c64e-44c8-a11e-685be880e456",
   "metadata": {},
   "source": [
    "# Bulid dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aaf5db40-0cac-4fd6-b777-46018389f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HTTP_PROXY\"] = \"http://192.168.45.100:3128\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://192.168.45.100:3128\"\n",
    "\n",
    "!pip install wfdb neurokit2 ts2vg --quiet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import natsort\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import random\n",
    "import time\n",
    "from itertools import cycle\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import librosa as lb\n",
    "import wfdb\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report, auc\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "133cf688-4b90-4986-bcb4-e47138db3d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# files = glob.glob('dataset/AMC_PeakLabel_refined2/Other_Ar*.npy')\n",
    "# len(files)\n",
    "# for f in files:\n",
    "#     src = f\n",
    "#     dst = f.replace('Other_Arr','OtherArr')\n",
    "#     shutil.move(src,dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be39d9f5-ed62-4903-b043-07a378fe1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob.glob('dataset/AMC_PeakLabel_refined2/*.npy')\n",
    "# arr = []\n",
    "\n",
    "# for f in files:\n",
    "#     saved = np.load(f'{f}',allow_pickle=True)\n",
    "#     saved = saved.item()\n",
    "#     arr.append(saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab385f7d-46c7-4009-b891-fbefbe1a2887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import natsort\n",
    "# files = natsort.natsorted(glob.glob('dataset/MIT-BIH_NPY/test/*.npy'))\n",
    "# arr = []\n",
    "\n",
    "# for f in files:\n",
    "#     saved = np.load(f'{f}',allow_pickle=True)\n",
    "#     for i in saved:# saved = saved.item()\n",
    "#         arr.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f55ae4c2-0a20-4207-83f6-d8e594b4ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "066bf02c-f461-4193-9af1-861af9e33e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('dataset/mit-bih-arrhythmia-database-1.0.0_testSeg.npy',arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c2180bd5-d1a7-4b84-8482-19306486cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob.glob('dataset/AMC_PeakLabel_refined2/*.npy')\n",
    "\n",
    "# for f in files:\n",
    "#     saved = np.load(f'{f}',allow_pickle=True)\n",
    "#     saved = saved.item()\n",
    "#     # plt.plot(saved['signal'])\n",
    "    \n",
    "#     fname_temp = f.split('/')[-1].split('at0.')[0].split('_')[1:]\n",
    "#     f_original = []\n",
    "#     for i in range(len(fname_temp)):\n",
    "#         f_original.append(fname_temp[i])\n",
    "#         if len(fname_temp)-i != 1:\n",
    "#             f_original.append('_')\n",
    "    \n",
    "#     f_original = \"\".join(f_original)\n",
    "#     s_original = glob.glob(f'dataset/AMC/**/*{f_original}*.csv')\n",
    "#     # print(len(s_original),\"\".join(f_original))\n",
    "#     # if len(s_original)==1:\n",
    "#     #     s_original = pd.read_csv(s_original[0])\n",
    "#     #     s_original = s_original['EKG'].to_numpy()\n",
    "#     #     s_original = lb.resample(s_original, orig_sr=125, target_sr=360)\n",
    "#     # else:\n",
    "#     #     print('err', len(s_original), s_original, fname_temp, f_original)    \n",
    "\n",
    "#     s_original = pd.read_csv(s_original[0])\n",
    "#     s_original = s_original['EKG'].to_numpy()\n",
    "#     s_original = lb.resample(s_original, orig_sr=125, target_sr=360)\n",
    "\n",
    "#     plt.figure(figsize=(20,4))\n",
    "#     plt.plot(saved['signal'],label='original')\n",
    "#     plt.plot(s_original,label='resample')\n",
    "#     plt.scatter(saved['idx_Normal'],s_original[saved['idx_Normal']])\n",
    "#     plt.scatter(saved['idx_PVC'],s_original[saved['idx_PVC']])\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "#     # saved['signal'] = s_original\n",
    "#     # np.save(f,saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8a515c7e-28c5-4ef0-87fd-cc1478662c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.load('dataset/european-st-t-database-1.0.0_testSeg.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "340bd785-d283-4b74-ae95-522e853020a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(a[0]['signal'])\n",
    "# plt.scatter(a[0]['idx_Normal'],a[0]['signal'][a[0]['idx_Normal']],color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "400ad666-dff3-42eb-bf6a-9c6843fcb25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob.glob('dataset/AMC_PeakLabel_refined3/*.npy')\n",
    "\n",
    "# for f in files:\n",
    "#     saved = np.load(f'{f}',allow_pickle=True)\n",
    "#     saved = saved.item()\n",
    "#     # plt.plot(saved['signal'])\n",
    "    \n",
    "#     fname_temp = f.split('/')[-1].split('at0.')[0].split('_')[1:]\n",
    "#     f_original = []\n",
    "#     for i in range(len(fname_temp)):\n",
    "#         f_original.append(fname_temp[i])\n",
    "#         if len(fname_temp)-i != 1:\n",
    "#             f_original.append('_')\n",
    "    \n",
    "#     f_original = \"\".join(f_original)\n",
    "#     s_original = glob.glob(f'dataset/AMC_raw/**/*{f_original}*.csv')\n",
    "#     # print(len(s_original),\"\".join(f_original))\n",
    "#     # if len(s_original)==1:\n",
    "#     #     s_original = pd.read_csv(s_original[0])\n",
    "#     #     s_original = s_original['EKG'].to_numpy()\n",
    "#     #     s_original = lb.resample(s_original, orig_sr=125, target_sr=360)\n",
    "#     # else:\n",
    "#     #     print('err', len(s_original), s_original, fname_temp, f_original)    \n",
    "\n",
    "#     s_original = pd.read_csv(s_original[0])\n",
    "#     s_original = s_original['EKG'].to_numpy()\n",
    "#     # s_original = lb.resample(s_original, orig_sr=125, target_sr=360)\n",
    "    \n",
    "#     plt.figure(figsize=(20,4))\n",
    "#     # plt.plot(saved['signal'],label='original')\n",
    "#     plt.plot(s_original,label='resample')\n",
    "#     n = np.array(saved['idx_Normal']).astype(float)*0.3472222222222222\n",
    "#     n = n.astype(int)\n",
    "#     p = np.array(saved['idx_PVC']).astype(float)*0.3472222222222222\n",
    "#     p = p.astype(int)\n",
    "    \n",
    "#     plt.scatter(n,s_original[n],color='b')\n",
    "#     plt.scatter(p,s_original[p],color='r')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "    \n",
    "#     saved['sr']=125\n",
    "#     saved['signal'] = s_original\n",
    "#     saved['idx_Normal'] = list(n)\n",
    "#     saved['idx_PVC'] = list(p)\n",
    "#     np.save(f,saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bf4555-7c4f-4e7c-a578-ba7eba7a4f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b1d6c34e-91ee-4b39-b6f6-3409b4109306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved['idx_Normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd8826b2-288e-41d8-a270-97fd3730be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = 'Afib_A-Fib_candidate_G-01_181129_16_20181129174310_0at0.npy'\n",
    "# a = np.load(f'dataset/AMC_PeakLabel_refined/{fname}',allow_pickle=True)\n",
    "# a = a.item()\n",
    "# plt.plot(a['signal'])\n",
    "# a['signal'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6c7dafd3-553f-478f-8c58-2ddae6683ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname_temp = fname.split('_')[1:-1]\n",
    "# f = []\n",
    "# for i in range(len(fname_temp)):\n",
    "#     f.append(fname_temp[i])\n",
    "#     if len(fname_temp)-i != 1:\n",
    "#         f.append('_')\n",
    "        \n",
    "# fname_ = \"\".join(f)\n",
    "# print(fname_)\n",
    "\n",
    "# s = glob.glob(f'dataset/AMC/**/*{fname_}*.csv')\n",
    "# print(s)\n",
    "# s = pd.read_csv(s[0])\n",
    "# s = s['EKG'].to_numpy()\n",
    "\n",
    "# s_ = lb.resample(s, orig_sr=125, target_sr=360)\n",
    "# plt.plot(s,label='original')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# plt.plot(s_,label='resample')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# s_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9fdca357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sourcedata_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2ddb6b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIT-BIH DS1, DS2 setting\n",
    "# files = natsort.natsorted(glob.glob('/workspace/signal/EKG_PVC/dataset/MIT-BIH_NPY/*.npy'))\n",
    "# import shutil\n",
    "\n",
    "# for f in files:\n",
    "#     p = f.split('/')[-1].split('.')[-2][-3:]\n",
    "#     if p in train_pids:\n",
    "#         print('train', p)\n",
    "#         src = f\n",
    "#         dst = '/workspace/signal/EKG_PVC/dataset/MIT-BIH_NPY/train/'+p+'.npy'\n",
    "#         shutil.copy(src,dst)\n",
    "#     elif p in test_pids:\n",
    "#         print('test', p)\n",
    "#         src = f \n",
    "#         dst = '/workspace/signal/EKG_PVC/dataset/MIT-BIH_NPY/test/'+p+'.npy'\n",
    "#         shutil.copy(src,dst)\n",
    "# # files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b52cf39",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "249aa8b9-2c8b-4812-bcc5-470b6ed61052",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourcedata_path = '/workspace/signal/EKG_PVC/dataset/mit-bih-arrhythmia-database-1.0.0'\n",
    "header_files = [os.path.basename(x) for x in glob.glob(os.path.join(sourcedata_path, '*.hea'))]\n",
    "\n",
    "pids = sorted([x.split('.')[0] for x in header_files])\n",
    "pids.remove('102')\n",
    "pids.remove('104')\n",
    "pids.remove('107')\n",
    "pids.remove('217')\n",
    "len(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eac26a38-7f6e-4bf9-95ca-8d5e9ded761e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourcedata_path = 'dataset/mit-bih-normal-sinus-rhythm-database-1.0.0'\n",
    "header_files = [os.path.basename(x) for x in glob.glob(os.path.join(sourcedata_path, '*.hea'))]\n",
    "\n",
    "pids = sorted([x.split('.')[0] for x in header_files])\n",
    "len(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5746622a-0f1d-4817-bb8b-0b704d38581f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourcedata_path = 'dataset/fantasia-database-1.0.0'\n",
    "header_files = [os.path.basename(x) for x in glob.glob(os.path.join(sourcedata_path, '*.ecg'))]\n",
    "\n",
    "pids = sorted([x.split('.')[0] for x in header_files])\n",
    "len(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7df78041-9b0a-4424-86fd-6a9f96b0c2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourcedata_path = 'dataset/INCART'\n",
    "header_files = [os.path.basename(x) for x in glob.glob(os.path.join(sourcedata_path, '*.hea'))]\n",
    "\n",
    "pids = sorted([x.split('.')[0] for x in header_files])\n",
    "len(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bda21250-d245-4425-b521-f69dc9ebd8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourcedata_path = 'dataset/kim/MIT-BIH AFDB_MIT-BIH Atrial Fibrillation Database/files/'\n",
    "header_files = [os.path.basename(x) for x in glob.glob(os.path.join(sourcedata_path, '*.hea'))]\n",
    "\n",
    "pids = sorted([x.split('.')[0] for x in header_files])\n",
    "len(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3030686-8e91-4775-81a0-51e5285aa446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourcedata_path = 'dataset/kim/MIT-SVDB_MIT-BIH Supraventricular Arrhythmia Database/mit-bih-supraventricular-arrhythmia-database-1.0.0'\n",
    "header_files = [os.path.basename(x) for x in glob.glob(os.path.join(sourcedata_path, '*.hea'))]\n",
    "\n",
    "pids = sorted([x.split('.')[0] for x in header_files])\n",
    "len(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cb71f4-ea4a-4747-a8ec-a4fe6e51027c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourcedata_path = 'dataset/european-st-t-database-1.0.0'\n",
    "header_files = [os.path.basename(x) for x in glob.glob(os.path.join(sourcedata_path, '*.hea'))]\n",
    "\n",
    "pids = sorted([x.split('.')[0] for x in header_files])\n",
    "len(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618fc610-2573-43e2-9b13-d90358506c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourcedata_path = 'dataset/kim/CU Ventricular Tachyarrhythmia Database/cu-ventricular-tachyarrhythmia-database-1.0.0'\n",
    "header_files = [os.path.basename(x) for x in glob.glob(os.path.join(sourcedata_path, '*.hea'))]\n",
    "\n",
    "pids = sorted([x.split('.')[0] for x in header_files])\n",
    "len(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0704e5-feda-42f2-854b-1a2db2f96bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourcedata_path = 'dataset/kim/MIT-BIH Noise Stress Test Database/mit-bih-noise-stress-test-database-1.0.0'\n",
    "header_files = [os.path.basename(x) for x in glob.glob(os.path.join(sourcedata_path, '*.hea'))]\n",
    "\n",
    "pids = sorted([x.split('.')[0] for x in header_files])\n",
    "len(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410e0ca4-e651-4eb8-8472-ff5c59be33f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourcedata_path = 'dataset/kim/mit-bih-st-change-database/mit-bih-st-change-database-1.0.0/mit-bih-st-change-database-1.0.0'\n",
    "header_files = [os.path.basename(x) for x in glob.glob(os.path.join(sourcedata_path, '*.hea'))]\n",
    "\n",
    "pids = sorted([x.split('.')[0] for x in header_files])\n",
    "len(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb5b3d3-5d6e-4d0a-9bc3-a55d7a057e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourcedata_path = 'dataset/european-st-t-database-1.0.0'\n",
    "header_files = [os.path.basename(x) for x in glob.glob(os.path.join(sourcedata_path, '*.hea'))]\n",
    "\n",
    "pids = sorted([x.split('.')[0] for x in header_files])\n",
    "len(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d8636-4583-4d51-9652-63777a37e6af",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/kim/CPSC2020/data/A01.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/io/matlab/_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_like, mode), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m     \u001b[39m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/kim/CPSC2020/data/A01.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/signal/PVC-NET/20230216_preprocess_MIT_arrhythmia_final copy.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f77697a6172646c795f6d656e64656c222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6b6576696e406e6f6465332e6d6932726c2e636f227d7d/workspace/signal/PVC-NET/20230216_preprocess_MIT_arrhythmia_final%20copy.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f77697a6172646c795f6d656e64656c222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6b6576696e406e6f6465332e6d6932726c2e636f227d7d/workspace/signal/PVC-NET/20230216_preprocess_MIT_arrhythmia_final%20copy.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m sourcedata_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdataset/kim/CPSC2020/data/A01.mat\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f77697a6172646c795f6d656e64656c222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6b6576696e406e6f6465332e6d6932726c2e636f227d7d/workspace/signal/PVC-NET/20230216_preprocess_MIT_arrhythmia_final%20copy.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m sig \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mloadmat(sourcedata_path)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f77697a6172646c795f6d656e64656c222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6b6576696e406e6f6465332e6d6932726c2e636f227d7d/workspace/signal/PVC-NET/20230216_preprocess_MIT_arrhythmia_final%20copy.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m sourcedata_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdataset/kim/CPSC2020/ref/R01.mat\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f77697a6172646c795f6d656e64656c222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6b6576696e406e6f6465332e6d6932726c2e636f227d7d/workspace/signal/PVC-NET/20230216_preprocess_MIT_arrhythmia_final%20copy.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m lbl \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mloadmat(sourcedata_path)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/io/matlab/_mio.py:224\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[39mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    223\u001b[0m variable_names \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mvariable_names\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 224\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    225\u001b[0m     MR, _ \u001b[39m=\u001b[39m mat_reader_factory(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    226\u001b[0m     matfile_dict \u001b[39m=\u001b[39m MR\u001b[39m.\u001b[39mget_variables(variable_names)\n",
      "File \u001b[0;32m/usr/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/io/matlab/_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m@contextmanager\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     f, opened \u001b[39m=\u001b[39m _open_file(file_like, appendmat, mode)\n\u001b[1;32m     18\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[39myield\u001b[39;00m f\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/io/matlab/_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m appendmat \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m file_like\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.mat\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.mat\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_like, mode), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mReader needs file name or open file-like object\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     49\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/kim/CPSC2020/data/A01.mat'"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "sourcedata_path = 'dataset/kim/CPSC2020/data/A01.mat'\n",
    "sig = scipy.io.loadmat(sourcedata_path)\n",
    "sourcedata_path = 'dataset/kim/CPSC2020/ref/R01.mat'\n",
    "lbl = scipy.io.loadmat(sourcedata_path)\n",
    "\n",
    "s= lbl['ref'][0][0][0][:,0]\n",
    "v= lbl['ref'][0][0][1][:,0]\n",
    "sourcedata_path = 'dataset/kim/CPSC2020/ref/RPN_01.mat'\n",
    "lbl  = scipy.io.loadmat(sourcedata_path)\n",
    "r= lbl['R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023defea-8853-49bf-944e-21a45c52d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(sig['ecg'][:,0][:20000],alpha=0.5)\n",
    "# plt.scatter(s,sig['ecg'][:,0][s],label='s')\n",
    "# plt.scatter(v,sig['ecg'][:,0][v],label='v')\n",
    "plt.scatter(r[:60],sig['ecg'][:,0][r][:60],label='r')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0cf8e9-ef8e-4915-819b-d52f2c709bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c6152b-30ea-4456-a9af-5dc440347f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigs = natsort.natsorted(glob('dataset/AMC_Surgery_Patient_raw_20221111/Afib/*.npy'))\n",
    "# sig = np.load(sourcedata_path,allow_pickle=False)\n",
    "# plt.plot(sig[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f46620fa-7595-4535-b42e-fe423ab25a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bulid dummy label\n",
    "# # AMC 2nd\n",
    "# import numpy as np\n",
    "# import scipy.io\n",
    "# import natsort\n",
    "# from glob import glob\n",
    "# from tqdm.notebook import tqdm, trange\n",
    "\n",
    "# # sigs = natsort.natsorted(glob('dataset/AMC_ecg_sample_20220812/*.npz'))\n",
    "# sigs = natsort.natsorted(glob('/workspace/signal/EKG_PVC/dataset/AMC_Surgery_Patient_raw_20221111/Both/*.npy'))\n",
    "# print(len(sigs))\n",
    "\n",
    "# sec = 20\n",
    "# # sr = 125\n",
    "\n",
    "# dataset = []\n",
    "# for i in trange(0,len(sigs)):\n",
    "#     sourcedata_path = sigs[i]\n",
    "#     sig = np.load(sourcedata_path,allow_pickle=False)\n",
    "#     fname = sigs[i].split('/')[-1].split('.')[0]\n",
    "#     pid = fname\n",
    "#     # signal_total = sig['v']\n",
    "#     signal_total = sig[:,1]\n",
    "#     sr = int(1/(sig[1,0]-sig[0,0]))\n",
    "    \n",
    "#     for idx in range(0,len(signal_total), sr*sec):\n",
    "#         start = idx\n",
    "#         end = start+int(sr*sec)\n",
    "\n",
    "#         data = dict()\n",
    "#         signal = signal_total[start:end]\n",
    "    \n",
    "#         try:\n",
    "#             points_Normal = get_Rpeak(ecg_signal=signal, sampling_rate=sr, plot=False)\n",
    "#         except:\n",
    "#             points_Normal = []\n",
    "#             # plt.plot(signal)\n",
    "#             # plt.scatter(points_Normal,signal[points_Normal])\n",
    "#             # plt.show()\n",
    "            \n",
    "#         points_PVC = []\n",
    "#         points_Others = []                \n",
    "#         idx_Normal = np.array(points_Normal)\n",
    "#         idx_Normal = list(idx_Normal)\n",
    "#         idx_Others = np.array(points_Others)\n",
    "#         idx_PVC = np.array(points_PVC)\n",
    "        \n",
    "#         margin = sr*.2\n",
    "        \n",
    "#         for j in range(len(idx_PVC)):\n",
    "#             for k in reversed(range(len(idx_Normal))):\n",
    "#                 # print(k,idx_Normal[k],len(idx_Normal))\n",
    "#                 if idx_Normal[k] >= idx_PVC[j]-margin and idx_Normal[k]< idx_PVC[j]+margin:\n",
    "#                     del idx_Normal[k]\n",
    "#         for j in range(len(idx_Others)):\n",
    "#             for k in  reversed(range(len(idx_Normal))):\n",
    "#                 if idx_Normal[k] >= idx_Others[j]-margin and idx_Normal[k]< idx_Others[j]+margin:\n",
    "#                     del idx_Normal[k]\n",
    "                    \n",
    "#         idx_Normal = list(set(idx_Normal))\n",
    "#         idx_Normal.sort()\n",
    "#         idx_Normal = np.array(idx_Normal)\n",
    "#         idx_Artifact = np.array([])\n",
    "#         idx_Afib = np.array([])\n",
    "        \n",
    "#         symbol_Normal, symbol_Others, symbol_PVC, symbol_Artifact, symbol_Afib = [],[],[],[],[]        \n",
    "        \n",
    "#         data['pid'], data['signal'], data['idx_Normal'], data['idx_Others'], data['idx_PVC'], data['idx_Artifact'], data['idx_Afib'], data['time'] = pid, signal, idx_Normal, idx_Others, idx_PVC, idx_Artifact, idx_Afib, int(start/sr)\n",
    "#         data['symbol_Normal'], data['symbol_Others'], data['symbol_PVC'], data['symbol_Artifact'], data['symbol_Afib'] = symbol_Normal, symbol_Others, symbol_PVC, symbol_Artifact, symbol_Afib\n",
    "#         data['sr'] = sr\n",
    "        \n",
    "#         if len(idx_Normal)>=1:\n",
    "#             dataset.append(data)\n",
    "        \n",
    "# np.save(f'dataset/AMC_Surgery_Patient_raw_20221111_BOTH_testSeg.npy',dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "48709cbb-85ce-4872-b6cd-d060f75c830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.load('dataset/AMC_REALtestSeg.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b908a5e0-3dda-48f0-961b-fe8ab7a72c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(dataset[0]['signal'])\n",
    "# plt.scatter(dataset[0]['idx_Normal'],dataset[0]['signal'][dataset[0]['idx_Normal']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe949e2d",
   "metadata": {},
   "source": [
    "# define annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4bb816b0-9821-447b-bef4-a5326e2f81f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sec = 20\n",
    "\n",
    "# nonbeat = ['[','!',']','x','(',')','p','t','u','`','\\'','^','|','~','+','s','T','*','D','=','\"','@','Q','?']\n",
    "normal = ['·','N'] # normal\n",
    "# others = ['L','R','B','A','a','J','S','r','!','e','j','n','E','/','f','x'] # others as is\n",
    "others = ['L','R','B','A','a','J','S','r','!','e','j','n','E','/','f'] # others to be\n",
    "PVC = ['V','F'] # PVC\n",
    "artifact = ['|','Q','M', 'MISSB', 'P', 'PSE', 'T', 'TS'] # aux_note에 있음,  TS는 \n",
    "rhythm_normal = ['(N']\n",
    "rhythm_AFIB = ['(AFIB', '(AFL']\n",
    "rhythm_others = ['(AB','(B','(BII','(IVR','(NOD','(P','(PREX','(SBR','(SVTA','(T','(VT']\n",
    "rhythm_artifact = []\n",
    "\n",
    "# + in atr_sym : rhythm annotation\n",
    "# ~ in atr_sym : quality annotation\n",
    "# \" in atr_sym : peak artifact annotation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a11e8ed5-97f8-44ef-92aa-8e4a017c5200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.signal import butter, filtfilt, lfilter\n",
    "import neurokit2 as nk\n",
    "\n",
    "def get_Rpeak(ecg_signal, sampling_rate, plot=False):    \n",
    "    ecg_signal_ = remove_baseline_wander(ecg_signal, sampling_rate)\n",
    "    _, rpeaks = nk.ecg_peaks(ecg_signal_, method='hamilton2002', sampling_rate=sampling_rate, correct_artifacts = False)\n",
    "    signal = ecg_signal\n",
    "    idx_R = rpeaks['ECG_R_Peaks']\n",
    "    if plot:\n",
    "        plt.figure(figsize=(18,4))\n",
    "        plt.plot(signal,label='signal',color='grey',alpha=0.6)\n",
    "        plt.scatter(idx_R, signal[idx_R], color='orange',marker='o',label='Normal') if len(idx_R)>0 else idx_R\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return rpeaks['ECG_R_Peaks']\n",
    "\n",
    "def load_ecg(file):\n",
    "    \"\"\"\n",
    "    wfdb.rdrecord 를 이용해서 ecg 파일을 읽어옵니다.\n",
    "    \"\"\"\n",
    "    record = wfdb.rdrecord(file)    # load the ecg\n",
    "    print(file)\n",
    "    try:\n",
    "        annotation = wfdb.rdann(file, 'atr')    # load the annotation\n",
    "    except:\n",
    "        annotation = wfdb.rdann(file, 'ecg')    # load the annotation in case of fantasia dataset\n",
    "    p_signal = record.p_signal    # extract the signal\n",
    "    sr = record.fs\n",
    "    # print(record.sig_name)\n",
    "    return p_signal, annotation, sr\n",
    "\n",
    "def load_pid(pid):\n",
    "    file = os.path.join(sourcedata_path, pid)\n",
    "    p_signal, annotation, sr = load_ecg(file)\n",
    "    \n",
    "    if pid =='114' or 'fantasia' in file: # L2 순서가 잘못된 경우\n",
    "        p_signal = np.flip(p_signal, axis=1)\n",
    "        p_signal = p_signal[:,0] # only L2 is extracted\n",
    "    elif 'INCART' in file: # L2 순서가 잘못된 경우\n",
    "        p_signal = p_signal[:,1] # L2 is @1 in INCART dataset\n",
    "    else:\n",
    "        p_signal = p_signal[:,0] # only L2 is extracted\n",
    "    \n",
    "    # print(f'{file}, min {np.min(p_signal)}, 1% {np.percentile(p_signal,1)}, 5% {np.percentile(p_signal,5)}, mean {np.percentile(p_signal,50)}, 95% {np.percentile(p_signal,95)}, max {np.max(p_signal)}')\n",
    "        \n",
    "    return p_signal, annotation, sr\n",
    "    \n",
    "def getSample(pid, p_signal, annotation, sr=360, start=0, end=360*10, plot=True):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        pid (str): Patient ID\n",
    "        p_signal (float): original signal\n",
    "        annotation (class): wfdb class\n",
    "        sr (int, optional): sampling rate. Defaults to 360.\n",
    "        start (int, optional): start point. Defaults to 0.\n",
    "        end (_type_, optional): end point. Defaults to 360*10.\n",
    "        plot (bool, optional): display plot. Defaults to True.\n",
    "    \"\"\"\n",
    "    p_signal= np.nan_to_num(p_signal)\n",
    "    # extract symbols and annotation index\n",
    "    atr_sym = annotation.symbol\n",
    "    atr_index = annotation.sample  \n",
    "    aux_note = annotation.aux_note\n",
    "    subtype = annotation.subtype\n",
    "    \n",
    "    # build atr_rhythm\n",
    "    atr_rhythm = []\n",
    "\n",
    "    # activate to get rhythm annotation\n",
    "    rhythm = 0\n",
    "    for idx in range(len(atr_sym)):\n",
    "        aux_note[idx] = aux_note[idx].replace('\\x00','')\n",
    "        if atr_sym[idx] == '+' and aux_note[idx] in rhythm_normal: # 0 for Normal rhythm group\n",
    "            atr_rhythm.append(rhythm)\n",
    "            rhythm = 0\n",
    "        elif atr_sym[idx] == '+' and aux_note[idx] in rhythm_AFIB: # 1 for AFIB rhythm group\n",
    "            atr_rhythm.append(rhythm)\n",
    "            rhythm = 1              \n",
    "        elif atr_sym[idx] =='+' and aux_note[idx] in rhythm_others: # 2 for other rhythm\n",
    "            atr_rhythm.append(rhythm)\n",
    "            rhythm = 2\n",
    "        else:\n",
    "            atr_rhythm.append(rhythm)\n",
    "            \n",
    "    # build atr_rhythm\n",
    "    atr_quality = []\n",
    "\n",
    "    # activate to get quality annotation\n",
    "    quality = 0\n",
    "    for idx in range(len(aux_note)): # 0 cc 2 cn # 1 nc 3 nn # -1 U\n",
    "        aux_note[idx] = aux_note[idx].replace('\\x00','')\n",
    "        if atr_sym[idx] == '~' and (subtype[idx] == -1) : # -1 U\n",
    "            atr_quality.append(quality)\n",
    "            quality = 1\n",
    "        elif atr_sym[idx] == '~' and (subtype[idx] == 0 or subtype[idx] == 1 or subtype[idx] == 2 or subtype[idx] == 3) :\n",
    "            atr_quality.append(quality)\n",
    "            quality = 0\n",
    "        else:\n",
    "            atr_quality.append(quality)\n",
    "            \n",
    "    # cutout data with time\n",
    "    # start = 0 if start<=0 else start\n",
    "    # start = len(p_signal)-int(sr*sec) if start+int(sr*sec)>=len(p_signal) else start\n",
    "    # end = start+int(sr*sec)\n",
    "\n",
    "    points_Normal = []\n",
    "    points_Others = []\n",
    "    points_PVC = []\n",
    "    points_Artifact = []\n",
    "    points_Afib = []\n",
    "    \n",
    "    symbol_Normal = []\n",
    "    symbol_Others = []\n",
    "    symbol_PVC = []\n",
    "    symbol_Artifact = []\n",
    "    symbol_Afib = []\n",
    "    \n",
    "    # margin = sr\n",
    "        \n",
    "    for idx in range(len(atr_index)):\n",
    "        if atr_index[idx] in range(start,end):\n",
    "            if atr_sym[idx] in normal:\n",
    "                points_Normal.append(atr_index[idx])\n",
    "                symbol_Normal.append(atr_sym[idx])\n",
    "            if atr_sym[idx] in PVC:\n",
    "                points_PVC.append(atr_index[idx])\n",
    "                symbol_PVC.append(atr_sym[idx])\n",
    "            if aux_note[idx] in artifact:\n",
    "                points_Artifact.append(atr_index[idx])\n",
    "                symbol_Artifact.append(aux_note[idx])\n",
    "            if atr_sym[idx] in artifact:\n",
    "                points_Artifact.append(atr_index[idx])\n",
    "                symbol_Artifact.append(atr_sym[idx])\n",
    "            if atr_sym[idx] in others:\n",
    "                points_Others.append(atr_index[idx])\n",
    "                symbol_Others.append(atr_sym[idx])\n",
    "            if atr_rhythm[idx] == 1 and (atr_sym[idx] in normal or atr_sym[idx] in PVC or atr_sym[idx] in others):\n",
    "                points_Afib.append(atr_index[idx])\n",
    "                symbol_Afib.append(atr_sym[idx])\n",
    "            elif atr_rhythm[idx] == 2 and (atr_sym[idx] in normal or atr_sym[idx] in PVC or atr_sym[idx] in others):\n",
    "                points_Others.append(atr_index[idx])\n",
    "                symbol_Others.append(atr_sym[idx])\n",
    "    \n",
    "    R_Raw = list(points_Normal) + list(points_PVC) + list(points_Others) + list(points_Afib)\n",
    "    R_Raw = set(R_Raw)\n",
    "    R_Raw = list(R_Raw)\n",
    "    R_Raw.sort()\n",
    "    \n",
    "    R_Refine = list(np.array(points_Normal)-start) + list(np.array(points_PVC)-start) + list(np.array(points_Others)-start) + list(np.array(points_Afib)-start)\n",
    "    R_Refine = set(R_Refine)\n",
    "    R_Refine = list(R_Refine)\n",
    "    R_Refine.sort()\n",
    "    # print(f'R_Raw {R_Raw}')\n",
    "\n",
    "    # cleans data\n",
    "    if pid == '108':\n",
    "        ex_list = [595416, 619643]\n",
    "    elif pid == '116':\n",
    "        ex_list = [360251, 360550, 487855, 488126, 488388, 488586, 488923, 489191, 489452, 500886, 501156, 501421, 501686, 501967, 502231, 505723]\n",
    "    elif pid == '203':\n",
    "        ex_list = [536969, 537205, 537359]\n",
    "    elif pid == '208':\n",
    "        ex_list = [438292, 438464, 498195, 498442, 498665, 498864, 499084, 499292, 499495]\n",
    "    else:\n",
    "        ex_list = []\n",
    "    points_Normal = remove_value(points_Normal, ex_list)\n",
    "    points_Others = remove_value(points_Others, ex_list)\n",
    "    points_PVC    = remove_value(points_PVC, ex_list)\n",
    "    points_Afib   = remove_value(points_Afib, ex_list)        \n",
    "                \n",
    "    signal = p_signal[start:end]\n",
    "    idx_Normal = np.array(points_Normal)-start\n",
    "    idx_Others = np.array(points_Others)-start\n",
    "    idx_PVC = np.array(points_PVC)-start\n",
    "    idx_Artifact = np.array(points_Artifact)-start\n",
    "    idx_Afib = np.array(points_Afib)-start\n",
    "    \n",
    "    # plot\n",
    "    if plot:\n",
    "        plt.figure(figsize=(18,4))\n",
    "        plt.plot(signal,label='signal',color='grey',alpha=0.6)\n",
    "        plt.title(f'Time start {start/sr}sec, end {end/sr}sec\\n Counts Normals {len(points_Normal)}, PVC {len(points_PVC)}')\n",
    "        plt.scatter(idx_Normal, signal[idx_Normal], color='orange',marker='o',label='Normal') if len(idx_Normal)>0 else idx_Normal\n",
    "        plt.scatter(idx_PVC, signal[idx_PVC], color='r',marker='x',label='PVC') if len(idx_PVC)>0 else idx_PVC\n",
    "        plt.scatter(idx_Others, 0.9*signal[idx_Others], color='r',marker='o',label='others') if len(idx_Others)>0 else idx_Others\n",
    "        plt.scatter(idx_Afib, 1.1*signal[idx_Afib], color='black',marker='^',label='Afib') if len(idx_Afib)>0 else idx_Afib\n",
    "        plt.scatter(idx_Artifact, 1.2*signal[idx_Artifact], color='black',marker='s',label='Artifact') if len(idx_Artifact)>0 else idx_Artifact\n",
    "        for i in range(len(R_Refine)):\n",
    "            plt.text(R_Refine[i],signal[R_Refine[i]],R_Raw[i],alpha=0.8)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    data = dict()\n",
    "    data['pid'], data['signal'], data['idx_Normal'], data['idx_Others'], data['idx_PVC'], data['idx_Artifact'], data['idx_Afib'], data['time'] = pid, signal, idx_Normal, idx_Others, idx_PVC, idx_Artifact, idx_Afib, int(start/sr)\n",
    "    data['symbol_Normal'], data['symbol_Others'], data['symbol_PVC'], data['symbol_Artifact'], data['symbol_Afib'] = symbol_Normal, symbol_Others, symbol_PVC, symbol_Artifact, symbol_Afib\n",
    "    data['sr'] = sr\n",
    "    return data\n",
    "\n",
    "def remove_value(arr, values):\n",
    "    \"\"\"\n",
    "    arr: numpy array\n",
    "    values: 제거할 값들이 들어있는 리스트\n",
    "    \"\"\"\n",
    "    return np.delete(arr, np.where(np.in1d(arr, values)))\n",
    "\n",
    "def remove_baseline_wander(signal, fs):\n",
    "    \"\"\" remove_baseline_wander\n",
    "    Args:\n",
    "        signal (float): original signal\n",
    "        fs (int): sampling rate\n",
    "\n",
    "    Returns:\n",
    "        res : filtered signal\n",
    "    \"\"\"\n",
    "    \n",
    "    order = 4\n",
    "    nyq = 0.5 * fs\n",
    "    lowcut = 0.67 #0.5\n",
    "    highcut = 40\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    \n",
    "    res = filtfilt(b, a, signal)\n",
    "    return res\n",
    "\n",
    "def get_index_within_margin(base_list, target_list, margin= int(360*.27), plot=True):\n",
    "    \"\"\"\n",
    "    base_list: 기준 리스트\n",
    "    target_list: 검사할 리스트\n",
    "    margin: 허용 오차 범위\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for i, num in enumerate(target_list):\n",
    "        for base_num in base_list:\n",
    "            if abs(num - base_num) <= margin:\n",
    "                break\n",
    "        else:\n",
    "            result.append(num)\n",
    "    result = set(result)\n",
    "    result = list(result)\n",
    "    result.sort()\n",
    "    \n",
    "    if plot:\n",
    "        for r in result:\n",
    "            start = r-1000 \n",
    "            end = r+1000\n",
    "            if plot:\n",
    "                if start >= 0:\n",
    "                    plt.plot(data['signal'][start:end])\n",
    "                    plt.scatter(1000, data['signal'][r], color='r')\n",
    "                else:\n",
    "                    start = 0\n",
    "                    end = 2000\n",
    "                    plt.plot(data['signal'][start:end])\n",
    "                    plt.scatter(r, data['signal'][r], color='r')                \n",
    "                plt.title(f'pid {pid} num {r}')\n",
    "                plt.show()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6765b706-5952-4bd0-8b20-879a2567e3d3",
   "metadata": {},
   "source": [
    "# Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b058cf67-d5d8-4ffa-a397-c6afe528c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIT-BIH my split\n",
    "test_pids = ['106', '119', '123', '205', '221']\n",
    "pids.remove('106')\n",
    "pids.remove('119')\n",
    "pids.remove('123')\n",
    "pids.remove('205')\n",
    "pids.remove('222')\n",
    "\n",
    "\n",
    "# MIT-BIH DS1, DS2 setting\n",
    "# pids =       ['101','106','108','109','112','114','115','116','118','119','122',\n",
    "#               '124','201','203','205','207','208','209','215','220','223','230']\n",
    "# test_pids =  ['100','103','105','111','113','117','121','123','200','202','210',\n",
    "#               '212','213','214','219','221','222','228','231','232','233','234']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6865c6b4-8b51-438c-b9c2-b344afd447d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 8 5\n",
      "train_pids ['208', '201', '122', '202', '233', '118', '115', '223', '203', '221', '228', '200', '231', '215', '121', '103', '210', '213', '111', '230', '219', '207', '232', '100', '105', '220', '114', '113', '209', '101', '109'] \n",
      "valid_pids['108', '124', '116', '234', '212', '117', '214', '112'] \n",
      "test_pids['106', '119', '123', '205', '221']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import *\n",
    "\n",
    "train_pids, valid_pids = train_test_split(pids, test_size=0.2, random_state=4, shuffle=True)\n",
    "\n",
    "# train_pids = ['208',  '201',  '122',  '202',  '233',  '118',  '115',  '223',  '203',  '221',  '228',  '200',  '231',  '215',  '121',  '103', '212','213',  '111',  '230',  '219',  '207',  '232',  '100',  '105',  '220',  '114',  '113',  '209',  '101',  '109']\n",
    "# valid_pids = ['108', '124', '116', '234', '210', '117', '214', '112']\n",
    "print(len(train_pids),len(valid_pids),len(test_pids))\n",
    "print(f'train_pids {train_pids} \\nvalid_pids{valid_pids} \\ntest_pids{test_pids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bccfdf0e-ac86-4540-aaf5-db6126f36762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 201 202 The PVCs are uniform and late-cycle.  This record was taken from the same\n",
    "#  analog tape as record 201.\n",
    "# 203 The PVCs are multiform. There are QRS morphology changes in the upper channel due to axis shifts. There is considerable noise in both channels, including muscle artifact and baseline shifts.  This is a very difficult record, even for humans!    \n",
    "# 205 The PVCs are of two forms, one of which is much more common than the other 쉬움\n",
    "# 207 # 어려운 케이스 The PVCs are multiform.  Idioventricular rhythm appears following the longest episode of ventricular flutter.  The record ends during the episode of SVTA.\n",
    "# 208 The PVCs are uniform.  The couplets, many of which include a fusion PVC, are often seen in a bigeminal pattern. The triplets each consist of two PVCs and a fusion PVC.\n",
    "# 209 Aldomet, Hydrodiuril, Inderal A만 많음\n",
    "# 210 The PVCs are multiform. \n",
    "# 212 R만 많음 There is rate-related right bundle branch block which appears when the heart rate exceeds approximately 90 bpm.\n",
    "# 213 The PVCs are multiform and usually late-cycle, frequently resulting in fusion PVCs. The morphology of the fusion PVCs varies from almost normal to almost identical to that of the PVCs.\n",
    "# 214 The PVCs are multiform. There are two episodes of artifactual amplitude decrease and one occurrence of tape slippage.\n",
    "# 215 The PVCs are multiform. There are two very short occurrences of tape slippage (each less than one second in duration).\n",
    "# 217 The PVCs are multiform.\n",
    "# 219 The PVCs are multiform.\n",
    "# 220 Digoxin? easy\n",
    "# 221 The PVCs are multiform, but one form is much more common than the others.\n",
    "# 222 There are several intervals of high-frequency noise/artifact in both channels.\n",
    "# 223 The PVCs are multiform. \n",
    "# 228 The PVCs are multiform. \n",
    "# 230 Dilantin (PREX\n",
    "# 231 MISSB\n",
    "# 232 hard case\n",
    "# 233 The PVCs are multiform.\n",
    "# 234 PVC uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2d44e8-f795-4dd4-a04b-d45711ad6ea3",
   "metadata": {},
   "source": [
    "# Check data is well loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9682f8af-b44d-4c00-b1b5-57969b86b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check altifact\n",
    "pid = '201'\n",
    "p_signal, annotation, sr = load_pid(pid)\n",
    "data = getSample(pid, p_signal, annotation, sr, 0*sr, 20*sr, plot=True)\n",
    "original_Rpeak = list(data['idx_Normal'])+ list(data['idx_PVC'])\n",
    "original_Rpeak.sort()\n",
    "pt_Rpeak = get_Rpeak(ecg_signal=data['signal'], sampling_rate=sr, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0bc503-e566-4869-827d-514fb308cd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check altifact\n",
    "pid = '105'\n",
    "p_signal, annotation, sr = load_pid(pid)\n",
    "data = getSample(pid, p_signal, annotation, sr, 1280*sr, 1300*sr, plot=True)\n",
    "original_Rpeak = list(data['idx_Normal'])+ list(data['idx_PVC'])\n",
    "original_Rpeak.sort()\n",
    "pt_Rpeak = get_Rpeak(ecg_signal=data['signal'], sampling_rate=sr, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a2ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cleansing\n",
    "pid = '208'\n",
    "p_signal, annotation, sr = load_pid(pid)\n",
    "data = getSample(pid, p_signal, annotation, sr, 1380*sr, 1390*sr, plot=True)\n",
    "original_Rpeak = list(data['idx_Normal'])+ list(data['idx_PVC'])\n",
    "original_Rpeak.sort()\n",
    "pt_Rpeak = get_Rpeak(ecg_signal=data['signal'], sampling_rate=sr, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd6979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pid in pids: # train\n",
    "for pid in test_pids: # test\n",
    "    p_signal, annotation, sr = load_pid(pid)\n",
    "    data = getSample(pid, p_signal, annotation, sr, 0, len(p_signal), plot=False)\n",
    "    # data = getSample(pid, p_signal, annotation, sr, 0, 10000, plot=False)\n",
    "    original_Rpeak = list(data['idx_Normal'])+ list(data['idx_PVC'])\n",
    "    original_Rpeak.sort()\n",
    "    pt_Rpeak = get_Rpeak(ecg_signal=data['signal'], sampling_rate=sr, plot=False)\n",
    "    mismatch = get_index_within_margin(pt_Rpeak, original_Rpeak)\n",
    "    print(f'pid {pid} mismatch {mismatch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a3bb56-4883-4eb1-b4a1-89325ddfa859",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = '203'\n",
    "p_signal, annotation, sr = load_pid(pid)\n",
    "data = getSample(pid, p_signal, annotation, sr, sr*1485, sr*1495, plot=True)\n",
    "\n",
    "get_Rpeak(ecg_signal=data['signal'], sampling_rate=sr, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77674101-1a13-4df4-b1ce-a50ad3e92d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = '108'\n",
    "p_signal, annotation, sr = load_pid(pid)\n",
    "data = getSample(pid, p_signal, annotation, sr, sr*900, sr*920, plot=True)\n",
    "\n",
    "get_Rpeak(ecg_signal=data['signal'], sampling_rate=sr, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686698fa-47b3-4c78-a109-eced96e7029b",
   "metadata": {},
   "source": [
    "# build segmentation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "08f6e98c-3e77-4f3f-83c4-0b7e0519d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all\n",
    "interval = 3250\n",
    "\n",
    "def build_seg_dataset(pids, fname, interval, overlap=False):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        pids (list): pid lists\n",
    "        fname (str): dataset name\n",
    "        interval (int): time interval\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    for pid in tqdm(pids):\n",
    "        p_signal, annotation, sr = load_pid(pid)\n",
    "        print(f'pid: {pid},  rest {len(p_signal)} count of total dataset: {len(dataset)}')\n",
    "        \n",
    "        if overlap: # for overlap\n",
    "            interval = 3250\n",
    "            dt = 3250//2 # sr*interval//2 \n",
    "        else:\n",
    "            interval = 3250\n",
    "            dt = 3250 # sr*interval\n",
    "            \n",
    "        for idx in range(0, len(p_signal), dt): \n",
    "            start = idx\n",
    "            end = idx + interval\n",
    "            data = getSample(pid, p_signal, annotation, sr, start, end, plot=False)\n",
    "            if interval == len(data[\"signal\"]):\n",
    "                # print(f'start{start}, end{end} len{len(data[\"signal\"])}')\n",
    "                dataset.append(data)\n",
    "            else:\n",
    "                print('Rest of data was removed')\n",
    "\n",
    "    np.save(f'{fname}.npy',dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "963b36a6-2aec-46c5-abd0-06065790caea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/signal/EKG_PVC/dataset/mit-bih-arrhythmia-database-1.0.0/108\n",
      "pid: 108,  rest 650000 count of total dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# MITDB\n",
    "sec = 10\n",
    "# temp_pids = ['208']\n",
    "# build_seg_dataset(temp_pids, f\"/workspace/signal/PVC-NET/dataset/{sourcedata_path.split('/')[-1]}_train_20230216\",sec,True)\n",
    "# build_seg_dataset(train_pids,f\"/workspace/signal/PVC-NET/dataset/{sourcedata_path.split('/')[-1]}_train_20230216\",sec,True)\n",
    "build_seg_dataset(valid_pids,f\"/workspace/signal/PVC-NET/dataset/{sourcedata_path.split('/')[-1]}_valid_20230216\",sec)\n",
    "# build_seg_dataset(test_pids,f\"/workspace/signal/EKG_PVC/dataset/{sourcedata_path.split('/')[-1]}_test_20230216\",sec*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c1f23bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12369\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load('dataset/mit-bih-arrhythmia-database-1.0.0_train_20230216.npy',allow_pickle=True) # B x (C) x Signal\n",
    "\n",
    "print(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    # print(i,len(train_data[i]['signal']))\n",
    "    if len(train_data[i]['signal'])!=3250:\n",
    "        print(i,len(train_data[i]['signal']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(npy[0]['signal'])\n",
    "plt.plot(npy[1]['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa08237e-1913-41df-8226-f364a1616a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMAL_SINUS\n",
    "sec = 20\n",
    "build_seg_dataset(pids,f\"dataset/{sourcedata_path.split('/')[-1]}_testSeg\",sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faddb99-1876-47be-9186-5c025637f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FANTASIA\n",
    "sec = 20\n",
    "build_seg_dataset(pids,f\"dataset/{sourcedata_path.split('/')[-1]}_testSeg\",sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34890c62-6f47-41f7-806a-f69850f41318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCART\n",
    "sec = 20\n",
    "build_seg_dataset(pids,f\"dataset/{sourcedata_path.split('/')[-1]}_testSeg\",sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2cfae6-804d-4dec-b53d-e8ddfee33b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CU\n",
    "sec = 20\n",
    "build_seg_dataset(pids,f\"dataset/{sourcedata_path.split('/')[-1]}_testSeg\",sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84feb93d-d553-400a-8a60-5d4bfa84c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDB\n",
    "sec = 20\n",
    "build_seg_dataset(pids,f\"dataset/{sourcedata_path.split('/')[-1]}_testSeg\",sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a489a104-7984-47ea-b326-ffd7e0807ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVDB\n",
    "sec = 20\n",
    "build_seg_dataset(pids,f\"dataset/{sourcedata_path.split('/')[-1]}_testSeg\",sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865054f3-8079-4f40-b4b3-5f1cced7eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import natsort\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "sigs = natsort.natsorted(glob.glob('dataset/kim/CPSC2020/data/*.mat'))\n",
    "lbls = natsort.natsorted(glob.glob('dataset/kim/CPSC2020/ref/*.mat'))\n",
    "print(len(sigs),len(lbls))\n",
    "\n",
    "sec = 20\n",
    "sr = 400\n",
    "\n",
    "for i in trange(0,len(sigs)):\n",
    "    dataset = []\n",
    "    sig = scipy.io.loadmat(sigs[i])\n",
    "    lbl = scipy.io.loadmat(lbls[i])\n",
    "    pid = sigs[i].split('/')[-1].split('.')[0]\n",
    "    fname = sigs[i].split('/')[-1].split('.')[0]\n",
    "    signal_total = sig['ecg']\n",
    "    s= lbl['ref'][0][0][0][:,0]\n",
    "    v= lbl['ref'][0][0][1][:,0]\n",
    "\n",
    "    for idx in range(0,len(signal_total), sr*sec):\n",
    "        start = idx\n",
    "        end = start+int(sr*sec)\n",
    "\n",
    "        data = dict()\n",
    "        signal = signal_total[start:end][:,0]\n",
    "    \n",
    "        try:\n",
    "            points_Normal = get_Rpeak(ecg_signal=signal, sampling_rate=sr, plot=False)\n",
    "        except:\n",
    "            points_Normal = []\n",
    "            # plt.plot(signal)\n",
    "            # plt.scatter(points_Normal,signal[points_Normal])\n",
    "            # plt.show()\n",
    "            \n",
    "        points_PVC = []\n",
    "        points_Others = []                \n",
    "        # points_Artifact = []\n",
    "        # points_Afib = []\n",
    "        for s_ in s:\n",
    "            if s_>=start and s_<end:\n",
    "                points_Others.append(s_-start)\n",
    "        for v_ in v:\n",
    "            if v_>=start and v_<end:\n",
    "                points_PVC.append(v_-start)          \n",
    "        \n",
    "        idx_Normal = np.array(points_Normal)\n",
    "        idx_Normal = list(idx_Normal)\n",
    "        idx_Others = np.array(points_Others)\n",
    "        idx_PVC = np.array(points_PVC)\n",
    "        \n",
    "        margin = sr*.2\n",
    "        \n",
    "        for j in range(len(idx_PVC)):\n",
    "            for k in reversed(range(len(idx_Normal))):\n",
    "                # print(k,idx_Normal[k],len(idx_Normal))\n",
    "                if idx_Normal[k] >= idx_PVC[j]-margin and idx_Normal[k]< idx_PVC[j]+margin:\n",
    "                    del idx_Normal[k]\n",
    "        for j in range(len(idx_Others)):\n",
    "            for k in  reversed(range(len(idx_Normal))):\n",
    "                if idx_Normal[k] >= idx_Others[j]-margin and idx_Normal[k]< idx_Others[j]+margin:\n",
    "                    del idx_Normal[k]\n",
    "                    \n",
    "        idx_Normal = list(set(idx_Normal))\n",
    "        idx_Normal.sort()\n",
    "        idx_Normal = np.array(idx_Normal)\n",
    "        idx_Artifact = np.array([])\n",
    "        idx_Afib = np.array([])\n",
    "        \n",
    "#         plt.figure(figsize=(20,4))\n",
    "#         plt.plot(signal[:sr*sec])\n",
    "#         plt.scatter(idx_Normal,signal[:sr*sec][idx_Normal],label='Normal')\n",
    "#         try:\n",
    "#             plt.scatter(idx_PVC,signal[:sr*sec][idx_PVC],label='PVC')\n",
    "#         except:\n",
    "#             0\n",
    "#         try:\n",
    "#             plt.scatter(idx_Others,signal[:sr*sec][idx_Others],label='others')\n",
    "#         except:\n",
    "#             0\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "\n",
    "        symbol_Normal, symbol_Others, symbol_PVC, symbol_Artifact, symbol_Afib = [],[],[],[],[]        \n",
    "        \n",
    "        data['pid'], data['signal'], data['idx_Normal'], data['idx_Others'], data['idx_PVC'], data['idx_Artifact'], data['idx_Afib'], data['time'] = pid, signal, idx_Normal, idx_Others, idx_PVC, idx_Artifact, idx_Afib, int(start/sr)\n",
    "        data['symbol_Normal'], data['symbol_Others'], data['symbol_PVC'], data['symbol_Artifact'], data['symbol_Afib'] = symbol_Normal, symbol_Others, symbol_PVC, symbol_Artifact, symbol_Afib\n",
    "        data['sr'] = sr\n",
    "        \n",
    "        if len(idx_Normal)>=1:\n",
    "            dataset.append(data)\n",
    "        \n",
    "    np.save(f'dataset/CPSC2020_{fname}_testSeg.npy',dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a5cf28-5ffe-4dc3-b72b-6a3cf5025d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls_r = natsort.natsorted(glob.glob('dataset/kim/CPSC2020/ref/RPN*.mat'))\n",
    "rs = []\n",
    "for l in lbls_r:    \n",
    "    lbl_r = scipy.io.loadmat(lbls_r[i])\n",
    "    r= lbl_r['R'][:,0]\n",
    "    rs.extend(r)\n",
    "len(lbls_r), len(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f6e40e-5ab2-496b-9892-7fb78d13182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import natsort\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "sigs = natsort.natsorted(glob.glob('dataset/kim/CPSC2020/data/*.mat'))\n",
    "lbls = natsort.natsorted(glob.glob('dataset/kim/CPSC2020/ref/R??.mat'))\n",
    "lbls_r = natsort.natsorted(glob.glob('dataset/kim/CPSC2020/ref/RPN*.mat'))\n",
    "\n",
    "print(len(sigs),len(lbls),len(lbls_r))\n",
    "\n",
    "sr = 400\n",
    "\n",
    "dataset = []\n",
    "for i in trange(0,len(sigs)):\n",
    "    sig = scipy.io.loadmat(sigs[i])\n",
    "    lbl = scipy.io.loadmat(lbls[i])\n",
    "    lbl_r = scipy.io.loadmat(lbls_r[i])\n",
    "    pid = sigs[i].split('/')[-1].split('.')[0]\n",
    "    fname = sigs[i].split('/')[-1].split('.')[0]\n",
    "    signal_total = sig['ecg']\n",
    "    s= lbl['ref'][0][0][0][:,0]\n",
    "    v= lbl['ref'][0][0][1][:,0]\n",
    "    r= lbl_r['R'][:,0]\n",
    "\n",
    "    for idx in range(0,len(signal_total), sr*sec):\n",
    "        start = idx\n",
    "        end = start+int(sr*sec)\n",
    "\n",
    "        data = dict()\n",
    "        signal = signal_total[start:end][:,0]\n",
    "    \n",
    "        # try:\n",
    "        #     points_Normal = get_Rpeak(ecg_signal=signal, sampling_rate=sr, plot=False)\n",
    "        # except:\n",
    "        #     points_Normal = []\n",
    "            # plt.plot(signal)\n",
    "            # plt.scatter(points_Normal,signal[points_Normal])\n",
    "            # plt.show()\n",
    "        \n",
    "        points_Normal = []\n",
    "        points_PVC = []\n",
    "        points_Others = []                \n",
    "        # points_Artifact = []\n",
    "        # points_Afib = []\n",
    "        for r_ in r:\n",
    "            if r_>=start and r_<end:\n",
    "                points_Normal.append(r_-start)\n",
    "        for s_ in s:\n",
    "            if s_>=start and s_<end:\n",
    "                points_Others.append(s_-start)\n",
    "        for v_ in v:\n",
    "            if v_>=start and v_<end:\n",
    "                points_PVC.append(v_-start)          \n",
    "        \n",
    "        idx_Normal = np.array(points_Normal)\n",
    "        idx_Normal = list(idx_Normal)\n",
    "        idx_Others = np.array(points_Others)\n",
    "        idx_PVC = np.array(points_PVC)\n",
    "        \n",
    "        margin = sr*.2\n",
    "        \n",
    "        for j in range(len(idx_PVC)):\n",
    "            for k in reversed(range(len(idx_Normal))):\n",
    "                # print(k,idx_Normal[k],len(idx_Normal))\n",
    "                if idx_Normal[k] >= idx_PVC[j]-margin and idx_Normal[k]< idx_PVC[j]+margin:\n",
    "                    del idx_Normal[k]\n",
    "        for j in range(len(idx_Others)):\n",
    "            for k in  reversed(range(len(idx_Normal))):\n",
    "                if idx_Normal[k] >= idx_Others[j]-margin and idx_Normal[k]< idx_Others[j]+margin:\n",
    "                    del idx_Normal[k]\n",
    "                    \n",
    "        idx_Normal = list(set(idx_Normal))\n",
    "        idx_Normal.sort()\n",
    "        idx_Normal = np.array(idx_Normal)\n",
    "        idx_Artifact = np.array([])\n",
    "        idx_Afib = np.array([])\n",
    "        \n",
    "        # plt.figure(figsize=(20,4))\n",
    "        # plt.plot(signal[:sr*sec])\n",
    "        # plt.scatter(idx_Normal,signal[:sr*sec][idx_Normal],label='Normal')\n",
    "        # try:\n",
    "        #     plt.scatter(idx_PVC,signal[:sr*sec][idx_PVC],label='PVC')\n",
    "        # except:\n",
    "        #     0\n",
    "        # try:\n",
    "        #     plt.scatter(idx_Others,signal[:sr*sec][idx_Others],label='others')\n",
    "        # except:\n",
    "        #     0\n",
    "        # plt.legend()\n",
    "        # plt.show()\n",
    "\n",
    "        symbol_Normal, symbol_Others, symbol_PVC, symbol_Artifact, symbol_Afib = [],[],[],[],[]        \n",
    "        \n",
    "        data['pid'], data['signal'], data['idx_Normal'], data['idx_Others'], data['idx_PVC'], data['idx_Artifact'], data['idx_Afib'], data['time'] = pid, signal, idx_Normal, idx_Others, idx_PVC, idx_Artifact, idx_Afib, int(start/sr)\n",
    "        data['symbol_Normal'], data['symbol_Others'], data['symbol_PVC'], data['symbol_Artifact'], data['symbol_Afib'] = symbol_Normal, symbol_Others, symbol_PVC, symbol_Artifact, symbol_Afib\n",
    "        data['sr'] = sr\n",
    "        \n",
    "        if len(idx_Normal)>=1:\n",
    "            dataset.append(data)\n",
    "        \n",
    "np.save(f'dataset/CPSC2020_testSeg_ver2.npy',dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825cbbbc-9400-42ba-8e29-ab518e092141",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1\n",
    "plt.plot(dataset[idx]['signal'])\n",
    "plt.scatter(dataset[idx]['idx_Normal'], dataset[idx]['signal'][dataset[idx]['idx_Normal']],label='normal')\n",
    "try:\n",
    "    plt.scatter(dataset[idx]['idx_Others'], dataset[idx]['signal'][dataset[idx]['idx_Others']],label='others')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    plt.scatter(dataset[idx]['idx_PVC'], dataset[idx]['signal'][dataset[idx]['idx_PVC']],label='pvc')\n",
    "except:\n",
    "    pass\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1298b2ae-a0c9-4599-86b9-79bf0be03b8f",
   "metadata": {},
   "source": [
    "# build classification dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90a33f-31a4-4949-9085-0d5adba9308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cls_dataset(pids,fname,sec,case):\n",
    "    dataset = []\n",
    "    for pid in tqdm(pids):\n",
    "        print(f'pid {pid} len(dataset) {len(dataset)}')\n",
    "        p_signal, annotation, sr = load_pid(pid)\n",
    "        \n",
    "        # extract symbols and annotation index\n",
    "        atr_sym = annotation.symbol\n",
    "        atr_index = annotation.sample  \n",
    "        aux_note = annotation.aux_note\n",
    "\n",
    "        # build atr_rhythm\n",
    "        atr_rhythm = []\n",
    "        rhythm = 0\n",
    "        for idx in range(len(atr_sym)):\n",
    "            aux_note[idx] = aux_note[idx].replace('\\x00','')\n",
    "            if atr_sym[idx] == '+' and aux_note[idx] in rhythm_normal: # Normal rhythm group\n",
    "                atr_rhythm.append(rhythm)\n",
    "                rhythm = 0\n",
    "            elif atr_sym[idx] == '+' and aux_note[idx] in rhythm_AFIB: # AFIB rhythm group\n",
    "                atr_rhythm.append(rhythm)\n",
    "                rhythm = 1\n",
    "            elif atr_sym[idx] =='+' and aux_note[idx] in rhythm_others:\n",
    "                atr_rhythm.append(rhythm)\n",
    "                rhythm = 2\n",
    "            else:\n",
    "                atr_rhythm.append(rhythm)\n",
    "\n",
    "        points_PVC = []\n",
    "        points_nonPVC = []\n",
    "        \n",
    "        for idx in range(len(atr_index)):\n",
    "            if atr_sym[idx] in PVC:\n",
    "                points_PVC.append(atr_index[idx])\n",
    "            elif atr_sym[idx] in normal or atr_sym[idx] in others:\n",
    "                # print(atr_sym[idx])\n",
    "                points_nonPVC.append(atr_index[idx])\n",
    "\n",
    "        if case == 'PVC':\n",
    "            lists = points_PVC            \n",
    "        if case == 'nonPVC':\n",
    "            lists = points_nonPVC\n",
    "            \n",
    "        i = 0\n",
    "        for p in lists:\n",
    "            start = p - int(sr*sec/2)\n",
    "            data = getSample(pid, p_signal, annotation, start, sr=sr, sec=sec, plot=True)\n",
    "            dataset.append(data)\n",
    "\n",
    "    np.save(f'dataset/{fname}.npy',dataset)\n",
    "    \n",
    "sec = 256/sr\n",
    "case = ['PVC', 'nonPVC']\n",
    "\n",
    "for c in case:\n",
    "    build_cls_dataset(train_pids,f\"dataset/{sourcedata_path.split('/')[-1]}_trainCls_{c}\",sec,c)\n",
    "    build_cls_dataset(valid_pids,f\"dataset/{sourcedata_path.split('/')[-1]}_validCls_{c}\",sec,c)\n",
    "    build_cls_dataset(test_pids, f\"dataset/{sourcedata_path.split('/')[-1]}_testCls_{c}\",sec,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99506dc-6122-47a4-8442-d4a1a3193076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for AMC test dataset\n",
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# files = glob.glob('experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/Afib_copy/*.png')\n",
    "\n",
    "# def rename(filelist):\n",
    "#     files = filelist\n",
    "#     for idx in range(len(files)):\n",
    "#         path = files[idx].split('/')[:-1]\n",
    "#         src = files[idx]\n",
    "#         dst = os.path.join(*path)+f'/{idx:02d}.png'\n",
    "#         # print(src)\n",
    "#         # print(dst)\n",
    "#         shutil.move(src,dst)\n",
    "\n",
    "# # folder = ['Afib', 'Other', 'VPC', 'Normal', 'Noise']\n",
    "# folder = ['Normal']\n",
    "# for f in folder:\n",
    "#     files = glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/{f}/*')\n",
    "#     rename(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea2eeb-ade0-4e60-817a-54d34909a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for AMC test dataset\n",
    "# import shutil\n",
    "# import os\n",
    "# import natsort\n",
    "# from tqdm import trange\n",
    "# folder = ['Afib', 'Other', 'VPC', 'Normal', 'Noise']\n",
    "# # folder = ['Noise']\n",
    "# # folder = ['Normal']\n",
    "\n",
    "# def copy(files):\n",
    "#     for idx in trange(len(files)):\n",
    "#         # fname = files[idx].split('/')[-1].split('.')[0].split('0at')[0]\n",
    "#         fname = files[idx].split('/')[-1].split('.')[0].replace('.png','.npy') # normal\n",
    "#         f = glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/npy/{fname}*')\n",
    "#         if len(f)!=0:\n",
    "#             f= f[0]\n",
    "#             src = f\n",
    "#             dst = f\"experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/{files[idx].split('/')[-2]}/{f.split('/')[-1]}\"\n",
    "#             # print('src',src)\n",
    "#             # print('dst',dst)\n",
    "#             shutil.copy(src,dst)\n",
    "#         else:\n",
    "#             print('error')\n",
    "        \n",
    "# for f in folder:\n",
    "#     files = natsort.natsorted(glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/{f}_copy/*.png'))\n",
    "#     copy(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c993847f-3da7-461e-bfa6-a3a56a7c5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import natsort\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "\n",
    "def display(data_dict):\n",
    "    data = data_dict\n",
    "    plt.plot(data['signal'],color='black',alpha=0.4)\n",
    "    plt.scatter(data['idx_Normal'],data['signal'][data['idx_Normal']],color='b',marker='o',label='NonPVC')\n",
    "    plt.scatter(data['idx_PVC'],data['signal'][data['idx_PVC']],color='r',marker='s',label='PVC')\n",
    "    \n",
    "    \n",
    "    all = data['idx_Normal'] + data['idx_PVC']\n",
    "    all.sort()\n",
    "    # print(all)\n",
    "    for i in range(len(all)):\n",
    "        plt.text(all[i],data['signal'][all[i]]+0.1,i) # 0.02 is just offset\n",
    "\n",
    "    for i in range(len(all)):\n",
    "        plt.text(all[i],data['signal'][all[i]]-.2,all[i]) # 0.02 is just offset\n",
    "    plt.legend()\n",
    "\n",
    "def refine(data, df, idx):\n",
    "    all = data['idx_Normal'] + data['idx_PVC']\n",
    "    all.sort()\n",
    "    print(f'total idx len(all)') if print_message else 1\n",
    "\n",
    "    manuallyCheck = False\n",
    "    \n",
    "    for i in range(len(df[idx])):\n",
    "        if not pd.isna(df[idx][i]):\n",
    "            try:\n",
    "                if '-' in df[idx][i]:   # make FP to normal\n",
    "                    idx_FP = int(df[idx][i].replace('-',''))\n",
    "                    print('refine FP',df[idx][i],idx_FP) if print_message else 1\n",
    "                    if all[idx_FP] in data['idx_PVC']:\n",
    "                        data['idx_PVC'].remove(all[idx_FP])\n",
    "                        data['idx_Normal'].append(all[idx_FP])\n",
    "                        data['idx_Normal'].sort()\n",
    "                elif '+' in df[idx][i]:  # make FN to positive\n",
    "                    idx_FN = int(df[idx][i].replace('+',''))\n",
    "                    print('refine FN',df[idx][i],idx_FN) if print_message else 1\n",
    "                    if all[idx_FN] in data['idx_Normal']:\n",
    "                        data['idx_Normal'].remove(all[idx_FN])\n",
    "                        data['idx_PVC'].append(all[idx_FN])\n",
    "                        data['idx_PVC'].sort()\n",
    "                elif 'end' in df[idx][i]:\n",
    "                    1\n",
    "                else:                 # make FN to non peak\n",
    "                    idx_FP = int(df[idx][i])\n",
    "                    print('remove item',data['pid'],df[idx][i]) if print_message else 1\n",
    "                    if all[idx_FP] in data['idx_PVC']:\n",
    "                        data['idx_PVC'].remove(all[idx_FP])\n",
    "                    if all[idx_FP] in data['idx_Normal']:\n",
    "                        data['idx_Normal'].remove(all[idx_FP])\n",
    "                        \n",
    "            except:  # 못 잡은 peak는 수동으로 해!!\n",
    "                print(f'!!! need manual check !!! file {data[\"pid\"]} idx {idx} annotation {df[idx][i]}')\n",
    "                manuallyCheck = True\n",
    "                \n",
    "    return data, manuallyCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1401552a-9446-4cf2-934c-372ae0daa04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/**/*refined*.npy')\n",
    "files = glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/Afib_copy/*refined*.npy')\n",
    "# files = glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/VPC_copy/*refined*.npy')\n",
    "# files = glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/Normal_copy/*refined*.npy')\n",
    "# files = glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/Other_copy/*refined*.npy')\n",
    "\n",
    "print(len(files))\n",
    "for f in files:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d424be-d780-47a7-a320-e6a5f0c7db56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afib_A-Fib_candidate_F-05_170906_07_20170906111626_0\n",
    "\n",
    "c = 'Afib'\n",
    "original = natsort.natsorted(glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/{c}_copy/*.png'))\n",
    "anonymized = natsort.natsorted(glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/{c}/*.png'))\n",
    "original_npy = natsort.natsorted(glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/{c}_copy/*.npy'))\n",
    "# print(c, len(original),len(anonymized),len(original_npy))\n",
    "\n",
    "ano = []\n",
    "ori = []\n",
    "ori_npy = []\n",
    "\n",
    "for i in range(len(original)):\n",
    "    for j in range(len(anonymized)):\n",
    "        a = anonymized[j]\n",
    "        o = original[i]\n",
    "        on = original_npy[i]\n",
    "        if filecmp.cmp(o,a):\n",
    "            ano.append(a)\n",
    "            ori.append(o)\n",
    "            ori_npy.append(on)\n",
    "            # print(o.split('/')[-1],on.split('/')[-1])\n",
    "\n",
    "ano, ori, ori_npy = zip(*natsort.natsorted(zip(ano, ori, ori_npy)))\n",
    "for idx in range(len(ano)):\n",
    "    print(idx,ano[idx],ori[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c18a96-caab-4aba-bcd1-f4cc3cc50047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatic refine\n",
    "# !pip install openpyxl\n",
    "import filecmp\n",
    "\n",
    "show = False\n",
    "print_message = False\n",
    "\n",
    "# cls = ['Afib', 'Other', 'VPC', 'Normal', 'Noise']\n",
    "# cls = ['Afib', 'Other', 'VPC', 'Normal']\n",
    "cls = ['Afib']\n",
    "# cls = ['Noise']\n",
    "# cls = ['Other']\n",
    "# cls = ['VPC']\n",
    "# cls = ['Normal']\n",
    "\n",
    "manuallyCheck_lists_ano = []\n",
    "manuallyCheck_lists = []\n",
    "manuallyCheck_messages = []\n",
    "counting = 0\n",
    "\n",
    "for c in cls:\n",
    "    csv = glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/{c}_copy/*.csv')[0]\n",
    "    df = pd.read_csv(csv)\n",
    "    df = df.T\n",
    "\n",
    "    original = natsort.natsorted(glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/{c}_copy/*.png'))\n",
    "    anonymized = natsort.natsorted(glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/{c}/*.png'))\n",
    "    original_npy = natsort.natsorted(glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/{c}_copy/*.npy'))\n",
    "    # print(c, len(original),len(anonymized),len(original_npy))\n",
    "    \n",
    "    ano = []\n",
    "    ori = []\n",
    "    ori_npy = []\n",
    "    \n",
    "    for i in range(len(original)):\n",
    "        for j in range(len(anonymized)):\n",
    "            a = anonymized[j]\n",
    "            o = original[i]\n",
    "            on = original_npy[i]\n",
    "            if filecmp.cmp(o,a):\n",
    "                ano.append(a)\n",
    "                ori.append(o)\n",
    "                ori_npy.append(on)\n",
    "                # print(o.split('/')[-1],on.split('/')[-1])\n",
    "                \n",
    "    ano, ori, ori_npy = zip(*natsort.natsorted(zip(ano, ori, ori_npy)))\n",
    "    \n",
    "    # for idx in range(len(df.columns)): # Noise\n",
    "    for idx in range(100):\n",
    "        print(idx, ano[idx],ori[idx], ori_npy[idx]) if print_message else 1\n",
    "        data = np.load(ori_npy[idx], allow_pickle=True).item()\n",
    "        data_refined, manuallyCheck = refine(data,df,idx)\n",
    "        # print(idx, ano[idx],ori[idx], ori_npy[idx])\n",
    "        \n",
    "        if manuallyCheck:\n",
    "            manuallyCheck_lists_ano.append(ano[idx])\n",
    "            manuallyCheck_lists.append(ori_npy[idx])\n",
    "            manuallyCheck_messages.append(df[idx])\n",
    "        else:\n",
    "            np.save(ori_npy[idx].replace('.npy','_refined.npy'), data_refined)\n",
    "            # np.save(ori_npy[idx], data_refined)\n",
    "        \n",
    "        if show:\n",
    "            plt.figure(figsize=(20,4))\n",
    "            plt.subplot(121)\n",
    "            display(data)\n",
    "            plt.title(f'Before check_{data[\"pid\"]}')\n",
    "            plt.subplot(122)\n",
    "            display(data_refined)\n",
    "            plt.title(f'After check_{idx}')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f16c6-c971-4d2d-8b08-ac8569fd70bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maunal refine\n",
    "idx = 0\n",
    "file_ano = manuallyCheck_lists_ano[idx]\n",
    "file = manuallyCheck_lists[idx]\n",
    "message = manuallyCheck_messages[idx]\n",
    "print(file_ano, file)\n",
    "print(message)\n",
    "\n",
    "data = np.load(file,allow_pickle=True).item()\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.title('original')\n",
    "display(data)\n",
    "plt.show()\n",
    "data_refined = data.copy()\n",
    "\n",
    "print('Normal',data_refined['idx_Normal'])\n",
    "print('PVC',data_refined['idx_PVC'])\n",
    "\n",
    "#################################\n",
    "# add or remove\n",
    "# data_refined['idx_PVC'].append(4560)\n",
    "# data_refined['idx_Normal'].append(4560)\n",
    "# data_refined['idx_PVC'] = []\n",
    "# data_refined['idx_Normal'].remove(2244)\n",
    "# data_refined['idx_Normal'].remove(1532)\n",
    "data_refined['idx_PVC'].remove(4239)\n",
    "data_refined['idx_Normal'].append(4201 )\n",
    "# data_refined['idx_PVC'].remove(4793)\n",
    "# data_refined['idx_PVC'].remove(6692)\n",
    "# data_refined['idx_Normal'].append(4793)\n",
    "# data_refined['idx_Normal'].append(6692)\n",
    "# data_refined['idx_Normal'].append(6490)\n",
    "# data_refined['idx_PVC'].append(2630)\n",
    "# data_refined['idx_Normal'].append(5760)\n",
    "#################################\n",
    "\n",
    "data_refined['idx_PVC'].sort()\n",
    "data_refined['idx_Normal'].sort()\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.title('revised')\n",
    "display(data_refined)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "Rpeak = get_Rpeak(data['signal'],360,True)\n",
    "print(Rpeak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c808e7c-2c69-471d-b980-6a3278879c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_refined['idx_PVC'] = []\n",
    "data_refined['idx_Normal'] = list(Rpeak)\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "display(data_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2765f7-e6b5-4306-8d6d-608e287dc327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save manually refined\n",
    "np.save(file.replace('.npy','_refined.npy'), data_refined)\n",
    "# maunal refine\n",
    "data = np.load(file.replace('.npy','_refined.npy'), allow_pickle=True).item()\n",
    "print(message)\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "display(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48cb193-4fe0-4320-b158-42b91992cb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/**/*Afib_A-Fib_candidate_F-05_180511_14_20180511171931_0*.npy')\n",
    "files\n",
    "# file = 'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/Afib_copy/PositiveCase_Afib_A-Fib_candidate_F-05_180511_14_20180511171931_0at1526026771.4139998_refined.npy'\n",
    "file = 'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/Afib_copy/PositiveCase_Afib_A-Fib_candidate_F-05_180511_14_20180511171931_0at1526026771.4139998_refined.npy'\n",
    "a = np.load(file,allow_pickle=True).item()\n",
    "plt.plot(a['signal'])\n",
    "plt.scatter(a['idx_Normal'],a['signal'][a['idx_Normal']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed416e3-9a27-4d32-94b5-7ca10c6c8546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob.glob(f'experiment/PVC_EfficientnetB4_nnblockEmbedded_InstanceNorm_DiceFocal_seed4_4class/result/**/*refined*.npy')\n",
    "\n",
    "# for file in files:\n",
    "#     data = np.load(file, allow_pickle=True).item()\n",
    "    \n",
    "#     plt.figure(figsize=(20,4))\n",
    "#     display(data)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b3fc6a-d805-48d5-944d-5da9bfd1952f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
